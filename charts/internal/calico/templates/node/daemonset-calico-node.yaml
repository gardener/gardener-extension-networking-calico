---
# This manifest installs the calico/node container, as well
# as the Calico CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
    gardener.cloud/role: system-component
    node.gardener.cloud/critical-component: "true"
  {{- if not .Values.autoscaling.staticRequests }}
  annotations:
    resources.gardener.cloud/preserve-resources: 'true'
  {{- end }}
spec:
  revisionHistoryLimit: 5
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 2
  template:
    metadata:
      labels:
        node.gardener.cloud/critical-component: "true"
        networking.gardener.cloud/to-public-networks: allowed
        networking.gardener.cloud/to-apiserver: allowed
        networking.gardener.cloud/to-dns: allowed
        k8s-app: calico-node
        gardener.cloud/role: system-component
      annotations:
        checksum/configmap-calico: {{ include (print $.Template.BasePath "/node/configmap-calico-config.yaml") . | sha256sum }}
    spec:
      nodeSelector:
        kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
        # Make sure calico-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: calico-node
      securityContext:
        seccompProfile:
          type: RuntimeDefault
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      priorityClassName: system-node-critical
      initContainers:
      {{- if eq .Values.global.overlayEnabled "false" }}
      - name: cleanup-routes
        image: {{ index .Values.images "calico-node" }}
        command: ["sh", "-c", "IFS=$'\n';for i in $(ip route | grep 'proto bird');do unset IFS;ip route del $i;done"]
        securityContext:
          privileged: true
      {{- end }}
      # This container installs the CNI binaries
      # and CNI network config file on each node.
      - name: install-cni
        image: {{ index .Values.images "calico-cni" }}
        command: ["/opt/cni/bin/install"]
        envFrom:
        - configMapRef:
            # Allow KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT to be overridden for eBPF mode.
            name: kubernetes-services-endpoint
            optional: true
        env:
          # Name of the CNI config file to create.
          - name: CNI_CONF_NAME
            value: "10-calico.conflist"
          # The CNI network config to install on each node.
          - name: CNI_NETWORK_CONFIG
            valueFrom:
              configMapKeyRef:
                name: calico-config
                key: cni_network_config
          # Set the hostname based on the k8s node name.
          - name: KUBERNETES_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          # CNI MTU Config variable
          - name: CNI_MTU
            valueFrom:
              configMapKeyRef:
                name: calico-config
                key: veth_mtu
          # Prevents the container from sleeping forever.
          - name: SLEEP
            value: "false"
        volumeMounts:
          #- mountPath: /host/opt/cni/bin
          #  name: cni-bin-dir
          - mountPath: /host/etc/cni/net.d
            name: cni-net-dir
          - mountPath: /host/secondary-bin-dir
            name: cni-bin-dir
        securityContext:
          privileged: true
      {{- if .Values.config.felix.bpf.enabled }}
      # This init container mounts the necessary filesystems needed by the BPF data plane
      # i.e. bpf at /sys/fs/bpf and cgroup2 at /run/calico/cgroup. Calico-node initialisation is executed
      # in best effort fashion, i.e. no failure for errors, to not disrupt pod creation in iptable mode.
      - name: mount-bpffs
        image: {{ index .Values.images "calico-node" }}
        command: ["calico-node", "-init", "-best-effort"]
        volumeMounts:
          - mountPath: /sys/fs
            name: sys-fs
            # Bidirectional is required to ensure that the new mount we make at /sys/fs/bpf propagates to the host
            # so that it outlives the init container.
            mountPropagation: Bidirectional
          - mountPath: /var/run/calico
            name: var-run-calico
            # Bidirectional is required to ensure that the new mount we make at /run/calico/cgroup propagates to the host
            # so that it outlives the init container.
            mountPropagation: Bidirectional
          # Mount /proc/ from host which usually is an init program at /nodeproc. It's needed by mountns binary,
          # executed by calico-node, to mount root cgroup2 fs at /run/calico/cgroup to attach CTLB programs correctly.
          - mountPath: /nodeproc
            name: nodeproc
            readOnly: true
        securityContext:
          privileged: true
      {{- end }}
      {{- if .Values.config.nonPrivileged }}
      - name: hostpath-init
        image: {{ index .Values.images "calico-node" }}
        command: ["sh", "-c", "calico-node -hostpath-init"]
        env:
        - name: NODE_USER_ID
          value: "999"
        securityContext:
          runAsUser: 0
        volumeMounts:
        - mountPath: /var/run
          name: var-run
          readOnly: false
        - mountPath: /var/lib
          name: var-lib
          readOnly: false
        - mountPath: /var/log
          name: var-log
          readOnly: false
      {{- end }}
      containers:
        # Runs calico-node container on each Kubernetes node. This
        # container programs network policy and routes on each
        # host.
        # Masquerade traffic to upstream DNS server
        {{- if eq .Values.global.snatToUpstreamDNSEnabled "true" }}
        - name: add-snat-rule-to-upstream-dns
          image: {{ index .Values.images "calico-node" }}
          imagePullPolicy: IfNotPresent
          securityContext:
            {{- if not .Values.config.nonPrivileged }}
            privileged: true
            {{- else }}
            privileged: false
            capabilities:
              add:
              - NET_ADMIN
            {{- end }}
          env:
          - name: POD_CIDR
            value: {{ .Values.global.podCIDR }}
          command:
          - /bin/sh
          - -c
          - |
            nft_kubelet_rules=$( (iptables-nft-save -t mangle; ip6tables-nft-save -t mangle ) 2>/dev/null | grep -E '^:(KUBE-IPTABLES-HINT|KUBE-KUBELET-CANARY)')
            if [ -n "$nft_kubelet_rules" ]; then
              backend="nft"
            else 
              backend="legacy"
            fi
            sleep 15
            while true; do
              for i in $(cat /etc/resolv.conf | grep nameserver | sed -n -e 's/^.*nameserver //p' ); do
                if [[ $i =~ .*:.* ]] && [[ ${POD_CIDR} =~ .*:.* ]]; then
                  ip6tables-$backend -t nat -C POSTROUTING -s ${POD_CIDR} -d $i/128 ! -o cali+ -m comment --comment "calico masquerade non-cluster" -j MASQUERADE 2>/dev/null \
                  || ip6tables-$backend -t nat -I POSTROUTING 1 -s ${POD_CIDR} -d $i/128 ! -o cali+ -m comment --comment "calico masquerade non-cluster" -j MASQUERADE
                elif [[ $i =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+$ ]] && [[ ${POD_CIDR} =~ ^[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+ ]]; then
                  iptables-$backend -t nat -C POSTROUTING -s ${POD_CIDR} -d $i/32 ! -o cali+ -m comment --comment "calico masquerade non-cluster" -j MASQUERADE 2>/dev/null \
                  || iptables-$backend -t nat -I POSTROUTING 1 -s ${POD_CIDR} -d $i/32 ! -o cali+ -m comment --comment "calico masquerade non-cluster" -j MASQUERADE
                fi
              done
              sleep 60
            done
          volumeMounts:
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
        {{- end }}
        # Ensure that the NetworkUnavailable condition is set correctly after startup
        # There may be a race between an old instance shutting down and a new instance starting up
        {{- if ne .Values.config.backend "none" }}
        - name: network-unavailable-condition-ensurer
          image: {{ index .Values.images "calico-node" }}
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: false
          env:
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            - name: IP
            {{- if .Values.config.ipv4.enabled }}
              value: "autodetect"
            {{- else }}
              value: "none"
            {{- end }}
            {{- if .Values.config.ipv4.enabled }}
            {{- if .Values.config.ipv4.autoDetectionMethod }}
            - name: IP_AUTODETECTION_METHOD
              value: "{{ .Values.config.ipv4.autoDetectionMethod }}"
            {{- end }}
            {{- end }}
            {{- if .Values.config.ipv6.enabled }}
            - name: IP6
              value: "autodetect"
            {{- if .Values.config.ipv6.autoDetectionMethod }}
            - name: IP6_AUTODETECTION_METHOD
              value: "{{ .Values.config.ipv6.autoDetectionMethod }}"
            {{- end }}
            {{- end }}
            - name: NO_DEFAULT_POOLS
              value: "true"
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting 30s for initialization to complete..."
              sleep 30
              echo "Ensuring NetworkUnavailable condition is set correctly..."
              calico-node -startup
              echo "Finished ensuring NetworkUnavailable condition is set correctly."
              while true; do
                echo "Sleeping for 1h..."
                sleep 3600
              done
        {{- end }}
        - name: calico-node
          image: {{ index .Values.images "calico-node" }}
          envFrom:
          - configMapRef:
              # Allow KUBERNETES_SERVICE_HOST and KUBERNETES_SERVICE_PORT to be overridden for eBPF mode.
              name: kubernetes-services-endpoint
              optional: true
          ports:
            {{- if .Values.config.monitoring.enabled }}
          - containerPort: {{  .Values.config.monitoring.felixMetricsPort }}
            name: metrics
            protocol: TCP
            {{- end}}
          env:
            {{- if eq .Values.config.ipam.type "host-local"}}
            - name: USE_POD_CIDR
              value: "true"
            {{- end }}
            {{- if .Values.config.monitoring.enabled }}
            - name: FELIX_PROMETHEUSMETRICSENABLED
              value: "{{ .Values.config.monitoring.enabled }}"
            - name: FELIX_PROMETHEUSMETRICSPORT
              value: "{{ .Values.config.monitoring.felixMetricsPort }}"
            {{- end }}
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: "kubernetes"
            # Typha support: controlled by the ConfigMap.
            - name: FELIX_TYPHAK8SSERVICENAME
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: typha_service_name
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: "k8s,bgp"
            - name: IP
            {{- if .Values.config.ipv4.enabled }}
              value: "autodetect"
            {{- else }}
              value: "none"
            {{- end }}
            {{- if .Values.config.ipv4.enabled }}
            - name: "CALICO_IPV4POOL_{{ .Values.config.ipv4.pool | upper }}"
              value: "{{ .Values.config.ipv4.mode }}"
            # The default IPv4 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            # no effect. This should fall within `--cluster-cidr`.
            - name: CALICO_IPV4POOL_CIDR
              value: "{{ .Values.global.podCIDR }}"
            # Auto-detect the BGP IP address.
            {{- if .Values.config.ipv4.autoDetectionMethod }}
            # On metal the ip is bound to the lo interface (routing to the host).
            - name: IP_AUTODETECTION_METHOD
              value: "{{ .Values.config.ipv4.autoDetectionMethod }}"
            {{- end }}
            {{- end }}
            {{- if .Values.config.ipv6.enabled }}
            - name: IP6
              value: "autodetect"
            - name: "CALICO_IPV6POOL_{{ .Values.config.ipv6.pool | upper }}"
              value: "{{ .Values.config.ipv6.mode }}"
            # The default IPv6 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            # no effect. This should fall within `--cluster-cidr`.
            - name: CALICO_IPV6POOL_CIDR
              value: "{{ .Values.global.podCIDRv6 }}"
            # Auto-detect the BGP IP address.
            {{- if .Values.config.ipv6.autoDetectionMethod }}
            # On metal the ip is bound to the lo interface (routing to the host).
            - name: IP6_AUTODETECTION_METHOD
              value: "{{ .Values.config.ipv6.autoDetectionMethod }}"
            {{- end }}
            - name: CALICO_IPV6POOL_NAT_OUTGOING
              value: "{{ .Values.config.ipv6.natOutgoing }}"
            - name: CALICO_ROUTER_ID
              value: "hash"
            {{- end }}
            # Configure IPv6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: "{{ .Values.config.ipv6.enabled }}"
            # Set MTU for tunnel device used if ipip is enabled
            - name: FELIX_IPINIPMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Set MTU for the VXLAN tunnel device.
            - name: FELIX_VXLANMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Set MTU for the Wireguard tunnel device.
            - name: FELIX_WIREGUARDMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            {{- if not .Values.global.vxlanEnabled }}
            - name: FELIX_IPINIPENABLED
              value: "{{ .Values.config.felix.ipinip.enabled }}"
            {{- end }}
            # Enable eBPF dataplane mode.
            - name: FELIX_BPFENABLED
              value: "{{ .Values.config.felix.bpf.enabled }}"
            # Controls whether Felix will clean up the iptables rules created by the Kubernetes kube-proxy; should only be enabled if kube-proxy is not running.
            - name: FELIX_BPFKUBEPROXYIPTABLESCLEANUPENABLED
              value: "{{ .Values.config.felix.bpfKubeProxyIPTablesCleanup.enabled }}"
            - name: FELIX_HEALTHENABLED
              value: "true"
            # Limit NAT port range: https://github.com/projectcalico/felix/pull/1838
            - name: FELIX_NATPORTRANGE
              value: "32768:65535"
            {{- if eq .Values.global.snatToUpstreamDNSEnabled "true" }}
            - name: FELIX_CHAININSERTMODE
              value: "Append"
            {{- end }}
            {{- if .Values.config.ipv4.wireguard }}
            - name: FELIX_WIREGUARDENABLED
              value: "true"
            {{- end }}
            {{- if .Values.config.ipv6.wireguard }}
            - name: FELIX_WIREGUARDENABLEDV6
              value: "true"
            {{- end }}
            # Enable automatic management of kubeconfig used by CNI (required due to limited lifetime of service account tokens, BoundServiceAccountTokenVolume feature)
            - name: CALICO_MANAGE_CNI
              value: "true"
            {{- if .Values.global.vxlanEnabled }}
            - name: CALICO_IPV4POOL_IPIP
              value: "Never"
            - name:  FELIX_VXLANENABLED
              value: "true"
            {{- end }}
          securityContext:
            {{- if not .Values.config.nonPrivileged }}
            privileged: true
            {{- else }}
            runAsUser: 999
            runAsGroup: 0
            privileged: false
            capabilities:
              add:
              - NET_RAW
              - NET_ADMIN
              - NET_BIND_SERVICE
            {{- end }}
          resources:
            requests:
              cpu: {{ if and .Values.autoscaling.staticRequests .Values.autoscaling.resourceRequests.node.cpu }}{{ .Values.autoscaling.resourceRequests.node.cpu }}{{ else }}250m{{ end }}
              memory: {{ if and .Values.autoscaling.staticRequests .Values.autoscaling.resourceRequests.node.memory }}{{ .Values.autoscaling.resourceRequests.node.memory }}{{ else }}100Mi{{ end }}
            limits:
              memory: 2800Mi
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/calico-node
                - -shutdown
          livenessProbe:
            exec:
              command:
              - /bin/calico-node
              - -felix-live
              {{- if eq .Values.config.backend "bird" }}
              - -bird-live
              {{- end }}
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
            timeoutSeconds: 10
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -felix-ready
              {{- if eq .Values.config.backend "bird" }}
              - -bird-ready
              {{- end }}
            periodSeconds: 10
            timeoutSeconds: 10
          volumeMounts:
            # For maintaining CNI plugin API credentials.
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
              readOnly: false
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            {{- if not .Values.config.nonPrivileged }}
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
            {{- else }}
            - mountPath: /var/run
              name: var-run
              readOnly: false
            - mountPath: /var/lib
              name: var-lib
              readOnly: false
            - mountPath: /var/log
              name: var-log
              readOnly: false
            {{- end }}
            - name: policysync
              mountPath: /var/run/nodeagent
            {{- if .Values.config.felix.bpf.enabled }}
            # For eBPF mode, we need to be able to mount the BPF filesystem at /sys/fs/bpf so we mount in the
            # parent directory.
            - name: bpffs
              mountPath: /sys/fs/bpf
            {{- end }}
            - name: cni-log-dir
              mountPath: /var/log/calico/cni
              readOnly: true
      volumes:
        # Used by calico-node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        {{- if not .Values.config.nonPrivileged }}
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
            type: DirectoryOrCreate
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
            type: DirectoryOrCreate
        {{- else }}
        - name: var-run
          hostPath:
            path: /var/run
        - name: var-lib
          hostPath:
            path: /var/lib
        - name: var-log
          hostPath:
            path: /var/log
        {{- end }}
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        {{- if .Values.config.felix.bpf.enabled }}
        - name: sys-fs
          hostPath:
            path: /sys/fs/
            type: DirectoryOrCreate
        - name: bpffs
          hostPath:
            path: /sys/fs/bpf
            type: Directory
        # mount /proc at /nodeproc to be used by mount-bpffs initContainer to mount root cgroup2 fs.
        - name: nodeproc
          hostPath:
            path: /proc
        {{- end }}
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
            type: DirectoryOrCreate
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Used to access CNI logs.
        - name: cni-log-dir
          hostPath:
            path: /var/log/calico/cni
        # Used to create per-pod Unix Domain Sockets
        - name: policysync
          hostPath:
            type: DirectoryOrCreate
            path: /var/run/nodeagent
